# GeminiLongContext
This project demonstrates the application of Google's Gemini 1.5's large context window capabilities to analyze research trends across 2.6 million papers from the ArXiv database. Unlike traditional approaches that rely on vector databases or retrieval-augmented generation (RAG), this implementation leverages Gemini's ability to process extensive text directly while maintaining coherent understanding across content. The notebook showcases a sophisticated analysis pipeline that processes papers in optimized batches of 250,000 words, implements a rolling context cache, and employs a novel content validation system using content markers and overlap detection. The analysis focuses on AI-related categories including Computer Vision, Machine Learning, Natural Language Processing, and Statistical Machine Learning from 2018-2024, revealing significant trends in research focus and methodological approaches. The implementation achieves processing speeds exceeding 10,000 tokens per second while maintaining contextual understanding across the entire corpus. This repo is forked from my solution submitted to Kaggle competition https://www.kaggle.com/competitions/gemini-long-context. Please refer to the competition webpage or my original notebook at https://www.kaggle.com/code/mehrdadkaggle/gemini-arxiv-analyzer for more info.
